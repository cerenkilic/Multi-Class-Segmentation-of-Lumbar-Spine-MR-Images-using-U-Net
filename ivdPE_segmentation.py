# -*- coding: utf-8 -*-
"""segm_github.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_IeovmmTim_B2O4iFQOrXDWLafPXE2f7
"""

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

import os
import cv2
import numpy as np
mri_directory = 'enter your drive link.'
file_names = os.listdir(mri_directory)
file_names = sorted([file for file in file_names if file.endswith(".png")])
mask_file_names = [file.replace("-0", "") for file in file_names]

import os
import cv2
import numpy as np
from PIL import Image
from sklearn.preprocessing import MinMaxScaler

mri_directory = 'enter your drive link.'
mask_directory = 'enter your drive link.'

scaler = MinMaxScaler()
image_dataset = []
target_size = (256,256)
import os
import cv2
import numpy as np

image_dataset = []


for filename in file_names:
    if filename.endswith(".png"):

        image = cv2.imread(os.path.join(mri_directory, filename), 1)
        filename = filename.replace("-0", "")
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        resized_image = cv2.resize(image, target_size)
        image_dataset.append(resized_image)

image_dataset = np.array(image_dataset)

image_dataset = (image_dataset.astype('float32')) / 255

mask_directory = 'enter your drive link.'

scaler = MinMaxScaler()
target_size = (256,256)
import os
import cv2
import numpy as np

mask_dataset = []
i = 0
for filename in mask_file_names:
    if filename.endswith(".png"):
        i = i + 1
        print(i)
        image = cv2.imread(os.path.join(mask_directory, filename), 1)

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        resized_image = cv2.resize(image, target_size)

        mask_dataset.append(resized_image)


mask_dataset = np.array(mask_dataset)


image_dataset = np.array(image_dataset)

scaler = MinMaxScaler()
target_size = (256,256)
import os
import cv2
import numpy as np

mask_dataset = []

for filename in mask_file_names:
    if filename.endswith(".png"):

        image = cv2.imread(os.path.join(mask_directory, filename), 1)

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        resized_image = cv2.resize(image, target_size)

        mask_dataset.append(resized_image)

mask_dataset = np.array(mask_dataset)
image_dataset = np.array(image_dataset)

unique_values = np.unique(mask_dataset)
mask_count = len(unique_values)
mask_dataset.shape

#kontrol:
import matplotlib.pyplot as plt
import random
import numpy as np
image_num = random.randint(0, len(image_dataset))
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.imshow(image_dataset[image_num])
plt.subplot(1, 2, 2)
plt.imshow(mask_dataset[image_num])

IVD = np.array((255,255,255))
PE = np.array((100,100,100))
BG = np.array((0,0,0))
print(PE)
print(IVD)
print(BG)

def rgb_to_2D_label(label):

    label_seg = np.zeros(label.shape,dtype=np.uint8)
    label_seg [np.all(label == IVD,axis=-1)] = 0
    label_seg [np.all(label== PE,axis=-1)] = 1
    label_seg [np.all(label== BG,axis=-1)] = 2

    label_seg = label_seg[:,:,0]
    return label_seg

labels = []
for i in range(mask_dataset.shape[0]):
    label = rgb_to_2D_label(mask_dataset[i])
    labels.append(label)

labels = np.array(labels)
print(labels.shape)
labels = np.expand_dims(labels, axis=3)


print("Unique labels in label dataset are: ", np.unique(labels))

labels.shape

import random
import numpy as np
image_number = random.randint(0, len(image_dataset))
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(image_dataset[image_number])
plt.subplot(122)
plt.imshow(labels[image_number][:,:,0])
plt.show()

n_classes = len(np.unique(labels))
print(len(np.unique(labels)))
from keras.utils import to_categorical
labels_cat = to_categorical(labels, num_classes=n_classes)

labels_cat.shape
reshaped_labels = np.reshape(labels, (1545, 3))
reshaped_labels.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(image_dataset, labels_cat, test_size = 0.20, random_state = 42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)

import os
os.environ["SM_FRAMEWORK"] = "tf.keras"

from tensorflow import keras
import segmentation_models as sm #bunu uygulamadan import edilmiyor.

import segmentation_models as sm
from tensorflow.keras.metrics import MeanIoU
weights = [0.34, 0.34, 0.32]
dice_loss = sm.losses.DiceLoss(class_weights=weights)
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)

def jacard_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)

print(X_train.shape[1],X_train.shape[2],X_train.shape[3])
print(X_train.shape)

IMG_HEIGHT = X_train.shape[1]
IMG_WIDTH = X_train.shape[2]
IMG_CHANNELS = X_train.shape[3]
n_classes = 3
import tensorflow as tf
from tensorflow.keras.models import load_model
from keras.callbacks import CSVLogger
import numpy as np
from skimage.io import imread
from skimage.io import imshow
from skimage.transform import resize
from tqdm import tqdm
import random
import matplotlib.pyplot as plt
from keras import backend as K

optimizer = keras.optimizers.Adam(lr=0.0001)


inputs = tf.keras.layers.Input((IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))
print(inputs.shape)

s=tf.keras.layers.Lambda(lambda x: x/255)(inputs)


c1= tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',padding='same')(s)

c1= tf.keras.layers.Dropout(0.2)(c1)
c1= tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal',padding='same')(c1)

p1=tf.keras.layers.MaxPooling2D((2,2))(c1)

c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
c2 = tf.keras.layers.Dropout(0.2)(c2)
c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)

c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
c3 = tf.keras.layers.Dropout(0.2)(c3)
c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)

c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
c4 = tf.keras.layers.Dropout(0.2)(c4)
c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)


c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
c5 = tf.keras.layers.Dropout(0.3)(c5)
c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)

#Expansive path
u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
u6 = tf.keras.layers.concatenate([u6, c4])
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
c6 = tf.keras.layers.Dropout(0.2)(c6)
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)

u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
u7 = tf.keras.layers.concatenate([u7, c3])
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
c7 = tf.keras.layers.Dropout(0.2)(c7)
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)

u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
u8 = tf.keras.layers.concatenate([u8, c2])
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
c8 = tf.keras.layers.Dropout(0.2)(c8)
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)

u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
u9 = tf.keras.layers.concatenate([u9, c1], axis=3)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
c9 = tf.keras.layers.Dropout(0.2)(c9)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)
#####activation softmax oldu multiclassta
outputs = tf.keras.layers.Conv2D(n_classes, (1, 1), activation='softmax')(c9)


model = tf.keras.Model(inputs=[inputs], outputs=[outputs])
model.compile(optimizer=optimizer, loss=total_loss, metrics=['accuracy'])
model.summary()

callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=5,monitor='val_loss'),
    tf.keras.callbacks.ModelCheckpoint('enter your drive link.',verbose=1,save_best_only=True)]
############### model checkpoint
history = model.fit(X_train, y_train,
                    batch_size=32,
                    verbose=1,
                    epochs=100,
                    validation_data=(X_test, y_test),
                    shuffle=False,
                    callbacks=callbacks)

history.history??
import pandas as pd
hist_df = pd.DataFrame(history.history)
hist_csv_file = 'enter your drive link.'
with open(hist_csv_file, mode='w') as f:
    hist_df.to_csv(f)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, color='red', label='Training loss',linewidth=2)
plt.plot(epochs, val_loss, color='blue', label='Validation loss', linewidth=2)
plt.title('Training and Validation Loss (batch_size = 32)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, color='red', label='training acc',linewidth=2)
plt.plot(epochs, val_acc, color='blue', label = 'validation acc',linewidth=2)
plt.title('Training and Validation Accuracy (batch_size = 32)')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

#IOU
y_pred=model.predict(X_test)
y_pred_argmax=np.argmax(y_pred, axis=3)
y_test_argmax=np.argmax(y_test, axis=3)


#Using built in keras function for IoU
from keras.metrics import MeanIoU
n_classes = 5
IOU_keras = MeanIoU(num_classes=n_classes)
IOU_keras.update_state(y_test_argmax, y_pred_argmax)
print("Mean IoU =", IOU_keras.result().numpy())

import random
test_img_number = random.randint(0, len(X_test))
test_img = X_test[test_img_number]
ground_truth=y_test_argmax[test_img_number]

test_img_input=np.expand_dims(test_img, 0)
prediction = (model.predict(test_img_input))
predicted_img=np.argmax(prediction, axis=3)[0,:,:]


plt.figure(figsize=(12, 8))
plt.subplot(231)
plt.title('Testing Image')
plt.imshow(test_img)
plt.subplot(232)
plt.title('Testing Label')
plt.imshow(ground_truth)
plt.subplot(233)
plt.title('Prediction on test image')
plt.imshow(predicted_img)
plt.show()